# 双目相机
![](https://images.cnblogs.com/cnblogs_com/gemstone/201112/201112192015473934.png)
![](https://images.cnblogs.com/cnblogs_com/gemstone/201112/201112192015488493.png)

[计算机视觉基础1——视差与深度信息](http://www.cnblogs.com/gemstone/archive/2011/12/19/2293806.html)


# 目录
    1. 单目
    2. 双目
    3. RGBD

# 双目立体视觉
    相机标定————畸变矫正————立体校正————极线约束————立体匹配(关键步骤)————三角测量
    
> 立体匹配最基本的步骤：

    1）代价计算。
       计算左图一个像素和右图一个像素之间的代价（某种差值）。
       
    2）代价聚合。
       一般基于点之间的匹配很容易受噪声的影响，往往真实匹配的像素的代价并不是最低。
       所以有必要在点的周围建立一个window，让像素块和像素块之间进行比较，这样肯定靠谱些。
       代价聚合往往是局部算法或者半全局算法才会使用，
       全局算法抛弃了window，采用基于全图信息的方式建立能量函数。
       
    3）深度赋值。
       这一步可以区分局部算法与全局算法，局部算法直接优化代价聚合模型。
       而全局算法，要建立一个能量函数，能量函数的数据项往往就是代价聚合公式，例如DoubleBP。
       输出的是一个粗略的视差图。
       
    4）结果优化。
       对上一步得到的粗估计的视差图进行精确计算，策略有很多，
       例如plane fitting，BP，动态规划等。


    
## 局部方法
    Winner-takes-All
    赢者通吃————先入为主—————用户黏性
    局部最小
> 方法有：
    
    1. Block Matching 块匹配
    
    
    6. CSCA
    
# 半全局


# 全局


# 双目　ros 包 elas 
[wiki.ros elas_ros](http://wiki.ros.org/elas_ros)

[github code cyphy-elas-ros](https://github.com/jeffdelmerico/cyphy-elas-ros)

[普通工程 ELAS ](https://github.com/Ewenwan/ELAS)

[stereo_elas](https://github.com/HeYijia/stereo_elas)

[双目障碍物检测](https://github.com/Ewenwan/homemade_stereo_obstacle_detection)


[深度学习双目匹配 DispNet]()


## 可以建立　相机坐标系下的　点云
## 如需建立 世界坐标系下的点云　需要跟踪　每一帧图像的位姿变化　既需要配合　视觉里程计来使用
[viso2](http://wiki.ros.org/viso2)
# 机器人视觉　实验室　代码参考　
[ 机器人视觉　实验室　代码参考　](http://www.cs.utoronto.ca/~urtasun/SW/code.html)

# elas使用 
## 节点　Nodes
### 节点1. elas_ros Nodes
> 完成　双目视差匹配disparity matching, 生成当前相机坐标系下的点云point clouds 　 camera's local reference frame.
### 订阅的话题　Subscribed Topics
    a. <stereo>/left/<image> (sensor_msgs/Image)　　　　　　左图矫正后的图像　Left rectified stereo image. 

    b. <stereo>/right/<image> (sensor_msgs/Image)　　　　　右图矫正后的图像　Right rectified stereo image. 

    c. <stereo>/left/camera_info (sensor_msgs/CameraInfo) 左相机参数　Camera info for left camera. 

    4. <stereo>/right/camera_info (sensor_msgs/CameraInfo) 右相机参数　Camera info for right camera. 

### 发布的话题　Published Topics
    a. disparity (sensor_msgs/Image)　　视差　话题
       Image representing the calculated disparity at each point. 
        Note that the values are scaled to be in the range [0, 255] 

    b. point_cloud (sensor_msgs/PointCloud2)　左相机当前坐标系下　的点云地图
        The point cloud assosciated with the calculated disparity in the left camera's local reference frame. 

    c. frame_data (elas_ros/ElasFrameData)　　结构数据　　用于三维重建
        Frame data used for the point cloud concatenation process. See node pc_construction. 

### 参数　Parameters
    a. ~queue_size (int, default: 5)　　队列大小
        Length of the input queues for left and right camera synchronization. 

    b. ~approximate_sync (bool, default: false)　　同步
        Whether the node should use approximate synchronization of incoming messages. 
        Set to true if cameras do not have synchronised timestamps. 

### 节点2. pc_construction 三维重建
    This node concatenates the point clouds generated by the elas_ros node.
### 订阅的话题　Subscribed Topics
    <frame_data> (elas_ros/ElasFrameData)　　　结构数据　　用于三维重建
        The frame data generated by the elas_ros node. 

    <pose> (geometry_msgs/PoseStamped)　　　　相机姿态数据　　来自视觉里程计
        The pose transformation from base frame to pose frame. 
        This accounts for motion of the camera. This can typically be determined by appropriate visual odometry. 
        See usage notes below. 

### 发布的话题Published Topics
    point_cloud (sensor_msgs/PointCloud2)　世界坐标系下的点云地图
        The concatenated point cloud. 

### 参数　Parameters
    ~queue_size (int, default: 5)　　队列大小　
        Length of the input queues for frame data and pose synchronization. 
　
    ~approximate_sync (bool, default: false)　　同步
        Whether the node should use approximate synchronization of incoming messages. 
        Set to true if frame data and pose do not have synchronised timestamps. 

    base_frame_id (string)　　基坐标系
        The name of the base frame that the concatenated point cloud should be cast into. 

    pose_frame_id (string)　　相机位姿坐标系
        The name of the frame that the given pose transforms into. 

### 相机　图像处理流水线　ros包
[image_pipeline](https://github.com/jeffdelmerico/image_pipeline)

| Tables        | Are           | Cool  |
| ------------- |:-------------:| -----:|
| col 3 is      | right-aligned | $1600 |
| col 2 is      | centered      |   $12 |
| zebra stripes | are neat      |    $1 |

# 显示链接中带括号的图片
![][1]
[1]: http://latex.codecogs.com/gif.latex?\prod%20(n_{i})+1


# 单目 双目相机 实战

## 单目标定

## 双目标定

## 双目匹配
- [单目相机](monocular/calibration.cpp)
- [双目相机](stereo/stereo_calib.cpp)

# OpenCV提供了以下四种立体匹配算法的函数：

    1. 基于局部的块匹配    Block Matching（BM） StereoBM
    2. 半全局块匹配        Semi-Global Block Matching（SGBM） StereoSGBM
    >第一步对每一个Pixel使用块匹配BM进行匹配，得到了全部Pixel的disparity map。
    >第二步对Disparity map建立图，用Graph Cut对其进行全局优化。
    >利用Rectification将二维转化为一维
    3. 基于全局的图割      Graph Cut（GC）cvStereoGCState()
    4. 基于全局的 动态规划 Dynamic Programming（DP）cvFindStereoCorrespondence()

# 双目相机 算法
[ ADCensus, SGBM, BM算法参考](https://github.com/DLuensch/StereoVision-ADCensus)

[ELAS论文解析](https://www.cnblogs.com/sinbad360/p/6883623.html)

[ELAS代码](https://github.com/Ewenwan/ELAS)

[棋盘格](https://github.com/DLuensch/StereoVision-ADCensus/tree/master/Documents/chessboards)

## 双目相机 矫正 
    * 用法 ./Stereo_Calibr -w=6 -h=8  -s=24.3 stereo_calib.xml   
      我的  ./Stereo_Calibr -w=8 -h=10 -s=200 stereo_calib.xml
    * ./stereo_calib -w=9 -h=6 stereo_calib.xml 标准图像
    *  实际的正方格尺寸在程序中指定 const float squareSize = 2.43f;    
       2.43cm  mm为单位的话为 24.3  0.1mm为精度的话为   243 注意 标定结果单位(纲量)和此一致
[原理分析](https://www.cnblogs.com/polly333/p/5013505.html )
[原理分析2](http://blog.csdn.net/zc850463390zc/article/details/48975263)
 
### 径向畸变矫正 光学透镜特效  凸起                k1 k2 k3 三个参数确定

     Xp=Xd(1 + k1*r^2 + k2*r^4 + k3*r^6)
     Yp=Yd(1 + k1*r^2 + k2*r^4 + k3*r^6)

### 切向畸变矫正 装配误差                         p1  p2  两个参数确定

     Xp= Xd + ( 2*p1*y  + p2*(r^2 + 2*x^2) )
     Yp= Yd + ( p1 * (r^2 + 2*y^2) + 2*p2*x )
     r^2 = x^2+y^2
    
### 投影公式 世界坐标点 到 相机像素坐标系下
                                                  | Xw|
    *  | u|     |fx  0   ux 0|     |    R   T  |    | Yw|
    *  | v| =   |0   fy  uy 0|  *  |           | *  | Zw| = M*W
    *  | 1|     |0   0  1   0|     |   0 0  0 1|    | 1 |

[相机标定和三维重建](http://wiki.opencv.org.cn/index.php/Cv)

    *   像素坐标齐次表示(3*1)  =  内参数矩阵 齐次表示(3*4)  ×  外参数矩阵齐次表示(4*4) ×  物体世界坐标 齐次表示(4*1)
    *   内参数齐次 × 外参数齐次 整合 得到 投影矩阵  3*4    左右两个相机 投影矩阵 P1 = K1*T1   P2 = k2*T2
    *   世界坐标　W 　---->　左相机投影矩阵 P1 ------> 左相机像素点　(u1,v1,1)
    *               ----> 右相机投影矩阵 P２ ------> 右相机像素点　(u2,v2,1)

### Q为 视差转深度矩阵 disparity-to-depth mapping matrix 
    * Z = f*B/d       =   f    /(d/B)
    * X = Z*(x-c_x)/f = (x-c_x)/(d/B)
    * X = Z*(y-c_y)/f = (y-y_x)/(d/B)

[ Q为 视差转深度矩阵 参考](http://blog.csdn.net/angle_cal/article/details/50800775)

    *    Q= | 1   0    0         -c_x     |    Q03
    *       | 0   1    0         -c_y     |    Q13
    *       | 0   0    0          f       |    Q23
    *       | 0   0   -1/B   (c_x-c_x')/B |    c_x和c_x'　为左右相机　平面坐标中心的差值（内参数）
    *                   Q32        Q33

    *  以左相机光心为世界坐标系原点   左手坐标系Z  垂直向后指向 相机平面  
    *           |x|      | x-c_x           |     |X|
    *           |y|      | y-c_y           |     |Y|
    *   Q    *  |d| =    |   f             |  =  |Z|======>  Z'  =   Z/W =     f/((-d+c_x-c_x')/B)
    *           |1|      |(-d+c_x-c_x')/B  |     |W|         X'  =   X/W = ( x-c_x)/((-d+c_x-c_x')/B)
                                                             Y'  =   Y/W = ( y-c_y)/((-d+c_x-c_x')/B)
                                                            与实际值相差一个负号
 ## 双目 视差与深度的关系                                                         
    Z = f * T / D   
    f 焦距 量纲为像素点  
    T 左右相机基线长度 
    量纲和标定时 所给标定板尺寸 相同 
    D视差 量纲也为 像素点 分子分母约去，
    Z的量纲同 T
 
 ## 像素单位与 实际物理尺寸的关系
    * CCD的尺寸是8mm X 6mm，帧画面的分辨率设置为640X480，那么毫米与像素点之间的转换关系就是80pixel/mm
    * CCD传感器每个像素点的物理大小为dx*dy，相应地，就有 dx=dy=1/80
    * 假设像素点的大小为k x l，其中 fx = f / k， fy = f / (l * sinA)， 
      A一般假设为 90°，是指摄像头坐标系的偏斜度（就是镜头坐标和CCD是否垂直）。
    * 摄像头矩阵（内参）的目的是把图像的点从图像坐标转换成实际物理的三维坐标。因此其中的fx,y, cx, cy 都是使用类似上面的纲量。
    * 同样，Q 中的变量 f，cx, cy 也应该是一样的。

        参考代码　
        https://github.com/yuhuazou/StereoVision/blob/master/StereoVision/StereoMatch.cpp
        https://blog.csdn.net/hujingshuang/article/details/47759579

        http://blog.sina.com.cn/s/blog_c3db2f830101fp2l.html

## 视差快匹配代价函数：

     【1】对应像素差的绝对值和（SAD, Sum of Absolute Differences） 

     【2】对应像素差的平方和（SSD, Sum of Squared Differences）

     【3】图像的相关性（NCC, Normalized Cross Correlation） 归一化积相关算法

     【4】ADCensus 代价
