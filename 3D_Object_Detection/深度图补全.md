# 深度图补全
[参考](https://www.zhihu.com/search?type=content&q=%20ElasticFusion)

[代码](https://github.com/Ewenwan/DeepCompletionRelease)

# 深度图补全 深度图修补 化妆 美颜

    虽然RGB-D相机前景无限，但是受制于物理硬件的限制，目前深度相机输出的depth图还有很多问题，
    比如对于光滑物体表面反射、半/透明物体、深色物体、超出量程等都会造成深度图缺失。
    而且很多深度相机是大片的深度值缺失，这对于算法工程师来说非常头疼。
    因此，深度图补全一直是一个非常有用的研究方向，
    之前的文献大都只能补全比较小范围的深度缺失，对于较大深度值缺失的情况无能无力。

# 2018 CVPR 最新的一项研究deep depth completion
    不受RGB-D相机类型的限制，只需要输入一张RGB加一张depth图，可以补全任意形式深度图的缺失。
    对于算法工程师来说真的是喜大普奔啊，目前主要针对的是室内环境。
    
# 什么原理？
![](https://pic4.zhimg.com/v2-f2d2fdaaf8a063236bf9418291fee227_b.jpg)

    Deep depth completion算法流程如下，
    其输入是RGB-D相机拍摄的一张RGB图像和对应的深度图，
    然后根据分别训练好的两个网络（一个是针对RGB图表面法线的深度学习网络，一个是针对物体边缘遮挡的深度学习网络），
    预测该彩色图像中所有平面的表面法线和物体边缘遮挡。
    最后用深度图作为正则化，求解一个全局线性优化问题，最终得到补全的深度图。

# 数据集准备
![](https://pic3.zhimg.com/v2-e704bafc1a016437142c6b9a71f132aa_b.jpg)

    他们利用现有的消费级RGB-D相机拍摄的数据集（Matterport3D、ScanNet、SUN3D、SceneNN）先进行稠密的三维重建，然后再进行优化和渲染。
    虽然单一视角的深度图可能会有因为不同原因引起的缺失，但是经过多个不同视角的重建和优化，这些缺失的地方都被填补了。
    然后将其深度结果反投影回到输入深度图。最后得到的深度图就是groundtruth啦，简直完美！
    省时省力省钱，还顺带学习了稠密三维重建，就是这么棒！看看下面的图，
    还是比较形象的，黄色代表不同视点的图，红色是当前视点渲染后的深度图。


